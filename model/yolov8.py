# -*- coding: utf-8 -*-
"""yolov8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ezacUfIkI3rLb5sMTpP-AmurezWlrvOv
"""

# Step 1: Install the required library
!pip install ultralytics --quiet  # Install the YOLOv8 library

# Step 2: Import the necessary libraries
from ultralytics import YOLO
import cv2
import os

# Step 3: Load the YOLOv8 model
model_path = '/content/best.pt'  # Path to your YOLOv8 .pt file

try:
    model = YOLO(model_path)  # Load the YOLOv8 model
    print("Model loaded successfully!")
except Exception as e:
    print(f"Error loading model: {e}")

# Step 4: Upload an image for detection
from google.colab import files
uploaded = files.upload()

# Assume only one image is uploaded
image_path = next(iter(uploaded.keys()))  # Get the uploaded image path

# Step 5: Perform inference
results = model(image_path)  # Perform detection

# Step 6: Save the image with bounding boxes and labels
def save_annotated_image(results, output_path):
    """Save the image with bounding boxes and labels."""
    annotated_image = results[0].plot()  # Generate the annotated image
    output_file = os.path.join(output_path, "annotated_image.jpg")
    cv2.imwrite(output_file, annotated_image)
    print(f"Annotated image saved at: {output_file}")

# Specify the output path to save the image
output_path = "/content/"
save_annotated_image(results, output_path)

from google.colab import files
uploaded = files.upload()  # Upload yolov8.pt
!pip install flask flask-cors ultralytics pillow opencv-python-headless pyngrok

with open("app.py", "w") as f:
    f.write('''
from datetime import datetime
import os
from flask import Flask, jsonify, request, send_file
from flask_cors import CORS
from ultralytics import YOLO
from PIL import Image
import cv2
import numpy as np

# Initialize Flask app
app = Flask(__name__)
CORS(app)

# Load YOLOv8 model
MODEL_PATH = "/content/best.pt"  # Update with your YOLOv8 model path
model = YOLO(MODEL_PATH)

# Directory for saving annotated images
ANNOTATED_IMAGES_DIR = "annotated_images"
os.makedirs(ANNOTATED_IMAGES_DIR, exist_ok=True)

# --- API Endpoints ---

@app.route("/", methods=["GET"])
def home():
    return jsonify({
        "message": "YOLOv8 Waste Classification API is running!",
        "endpoints": {
            "/detect": "POST - Upload an image for detection"
        }
    })

@app.route("/detect", methods=["POST"])
def detect_objects():
    try:
        # Check if a file is provided
        if "file" not in request.files:
            return jsonify({"error": "No file provided"}), 400

        file = request.files["file"]

        # Load and preprocess the image
        image = Image.open(file.stream)
        image_np = np.array(image)

        # Perform inference
        results = model(image_np)
        result = results[0]

        # Annotate the image
        annotated_image = result.plot()
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        annotated_image_path = os.path.join(ANNOTATED_IMAGES_DIR, f"annotated_{timestamp}.jpg")
        cv2.imwrite(annotated_image_path, annotated_image)

        # Count object frequencies
        counts = {}
        for box in result.boxes:
            cls_id = int(box.cls)  # Class ID
            cls_name = model.names[cls_id]  # Class name
            counts[cls_name] = counts.get(cls_name, 0) + 1

        # Return annotated image and object counts
        return jsonify({
            "annotated_image_url": f"/download/{os.path.basename(annotated_image_path)}",
            "counts": counts
        })

    except Exception as e:
        return jsonify({"error": str(e)}), 500

@app.route("/download/<filename>", methods=["GET"])
def download_image(filename):
    file_path = os.path.join(ANNOTATED_IMAGES_DIR, filename)
    if os.path.exists(file_path):
        return send_file(file_path, mimetype="image/jpeg")
    else:
        return jsonify({"error": "File not found"}), 404

# Run the app
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000, debug=True)

''')

!python app.py

!pip install pyngrok

from pyngrok import ngrok

# Authenticate with ngrok using your authtoken
ngrok.set_auth_token("2phu7V2TrpodAmFOaQcpRUqaSBq_3JasoJR6gyWrfvMpU16Wt")

# Open a ngrok tunnel to the Flask app on port 5000
public_url = ngrok.connect(5000)
print(f"Public URL: {public_url}")

import requests

# URL of the API running locally or through ngrok
url = "https://2a21-34-145-200-77.ngrok-free.app/detect"  # Replace <your_ngrok_public_url> with your actual ngrok public URL

# Open the image file
image_path = "/content/-1x-1.jpg"
with open(image_path, "rb") as f:
    files = {'file': f}

    # Send POST request to detect objects in the image
    response = requests.post(url, files=files)

# Print the response status code
print(f"Response status code: {response.status_code}")

# Only try to decode JSON if the request was successful
if response.status_code == 200:
    try:
        print(response.json())
    except requests.exceptions.JSONDecodeError:
        print("Response content is not valid JSON.")
else:
    print(f"Request failed with status code: {response.status_code}")
    print(response.text) # Print the raw response content for debugging

# Base URL of the API
base_url = "https://2a21-34-145-200-77.ngrok-free.app"

# Relative path to the annotated image
image_path = "/download/annotated_20241203_130621.jpg"

# Complete URL to access the annotated image
complete_url = base_url + image_path

print(f"Download the annotated image from: {complete_url}")