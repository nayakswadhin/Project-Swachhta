# from fastapi import FastAPI, HTTPException, UploadFile, File
# from fastapi.middleware.cors import CORSMiddleware
# import torch
# import tensorflow as tf
# import numpy as np
# from PIL import Image
# import io

# app = FastAPI()

# # CORS Middleware
# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["*"],
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

# # Load YOLOv5 model
# model_yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', force_reload=True, trust_repo=True)
# object_classes = ['refrigerator', 'chair', 'bed', 'dining table', 'tv', 'bottle', 'sink', 'remote', 'bowl', 'cup', 'spoon', 'fork', 'wine glass', 'glass']
# prob_threshold = 0.2

# # Load TensorFlow models
# model_messy = tf.keras.models.load_model('messycleanmodel.h5')
# model_damage = tf.keras.models.load_model('DamageDetection.h5')
# model_stain = tf.keras.models.load_model('staindetection.h5')

# # Preprocess functions
# def preprocess_image(img: Image.Image, size: tuple = (150, 150)):
#     img = img.resize(size)
#     img = np.array(img) / 255.0
#     img = np.expand_dims(img, axis=0)
#     return img

# def preprocess_image2(img: Image.Image, size: tuple = (120, 120)):
#     img = img.resize(size)
#     img = np.array(img) / 255.0
#     img = np.expand_dims(img, axis=0)
#     return img


# @app.post("/messy_predict")
# async def predict_messy(file: UploadFile = File(...)):
#     try:
#         # Read the uploaded image file
#         image_bytes = await file.read()
#         img = Image.open(io.BytesIO(image_bytes))

#         # Preprocess and predict
#         img_array = preprocess_image(img)
#         prediction = model_messy.predict(img_array)
#         messy_score = float(prediction[0][0])
#         return {"result": messy_score}
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"Error in messy prediction: {e}")


# Run the application



# model for light detection

# -- coding: utf-8 --
"""energyefficiency.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kuvasnIUIBhR62NFvR48NLOxsXrrYmGt
"""

# from fastapi import FastAPI, UploadFile, File, HTTPException
# from typing import List
# import cv2
# import pandas as pd
# import numpy as np

# app = FastAPI()

# # Define your existing room attributes
# room_attributes = {
#     "Room_101": {"room_type": "working room", "room_occupancy": "medium", "room_kwh": 0.1},  # kWh per hour
#     "Room_102": {"room_type": "storage room", "room_occupancy": "small", "room_kwh": 0.05},
#     "Room_103": {"room_type": "break room", "room_occupancy": "large", "room_kwh": 0.2},
# }

# def is_light_on(frame, threshold=120):
#     gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
#     avg_brightness = np.mean(gray_frame)
#     return avg_brightness > threshold

# @app.post("/process_video")
# async def process_video(room_id: str, file: UploadFile = File(...)):
#     try:
#         # Check if room information exists for the provided room_id
#         if room_id not in room_attributes:
#             raise HTTPException(status_code=400, detail="Room information not found.")
        
#         # Read the uploaded video file
#         video_bytes = await file.read()
#         video_path = f"temp_{file.filename}"

#         # Save the uploaded video to a temporary file
#         with open(video_path, "wb") as f:
#             f.write(video_bytes)

#         # Initialize video processing variables
#         log_data = []
#         light_on = False
#         start_time = None
#         total_duration = 0
#         fps = 0

#         room_info = room_attributes.get(room_id, {})
#         if not room_info:
#             raise HTTPException(status_code=400, detail="Room information not found.")

#         room_type = room_info.get("room_type", "unknown")
#         room_occupancy = room_info.get("room_occupancy", "unknown")
#         room_kwh = room_info.get("room_kwh", 0)

#         # Read video and process frame by frame
#         cap = cv2.VideoCapture(video_path)
#         if not cap.isOpened():
#             raise HTTPException(status_code=500, detail="Error: Unable to open video file.")
        
#         fps = int(cap.get(cv2.CAP_PROP_FPS))
#         frame_count = 0

#         try:
#             while True:
#                 ret, frame = cap.read()
#                 if not ret:
#                     break

#                 frame_count += 1
#                 timestamp = frame_count / fps

#                 current_light_status = is_light_on(frame)

#                 if current_light_status != light_on:
#                     if current_light_status:
#                         start_time = timestamp
#                     else:
#                         if start_time is not None:
#                             duration = timestamp - start_time
#                             total_duration += duration
#                         start_time = None
#                     light_on = current_light_status

#         finally:
#             cap.release()
#             cv2.destroyAllWindows()

#         # Calculate energy usage and efficiency status
#         total_energy = (total_duration / 3600) * room_kwh
#         threshold = 8 * room_kwh
#         efficiency_status = "Inefficient" if total_energy > threshold else "Efficient"

#         log_data.append([room_id, room_type, room_occupancy, total_duration, total_energy, threshold, efficiency_status])

#         # Prepare and return results as a dictionary
#         result = {
#             "room_id": room_id,
#             "room_type": room_type,
#             "room_occupancy": room_occupancy,
#             "total_duration_seconds": total_duration,
#             "total_energy_kWh": total_energy,
#             "threshold_kWh": threshold,
#             "efficiency_status": efficiency_status
#         }

#         # Optionally, save results to a CSV file
#         df = pd.DataFrame(log_data, columns=[
#             "Room_ID", "Room_Type", "Room_Occupancy", "Total_Duration_Seconds",
#             "Total_Energy_kWh", "Threshold_kWh", "Efficiency_Status"
#         ])
#         df.to_csv(f"room_light_usage_summary_{room_id}.csv", index=False)

#         return result
#     except Exception as e:
#         raise HTTPException(status_code=500, detail=f"Error processing video: {e}")


# File: main.py
from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse
import pandas as pd
import prophet
import matplotlib.pyplot as plt
import os
import json

app = FastAPI(title="Energy Forecast API")

@app.get("/forecast")
async def create_forecast(file_path: str = "C:/Users/nayak/Downloads/extended_energy_data.csv"):
    try:
        # Verify file exists
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail=f"File not found at {file_path}")
        
        # Read the CSV file
        data = pd.read_csv(file_path)
        
        # Data preprocessing
        data['timestamp'] = pd.to_datetime(data['timestamp'])
        data = data.sort_values('timestamp')
        data['energyKWh'] = data['energyKWh'].fillna(data['energyKWh'].mean())
        
        # Prepare data for Prophet
        prophet_data = data[['timestamp', 'energyKWh']].rename(columns={'timestamp': 'ds', 'energyKWh': 'y'})
        
        # Split data
        train_size = int(0.8 * len(prophet_data))
        train = prophet_data[:train_size]
        test = prophet_data[train_size:]
        
        # Create and fit Prophet model
        model = prophet.Prophet(
            seasonality_mode='additive',
            yearly_seasonality=True,
            weekly_seasonality=True,
            daily_seasonality=True
        )
        model.fit(train)
        
        # Generate forecast
        future = model.make_future_dataframe(periods=len(test), freq='D')
        forecast = model.predict(future)
        
        # Prepare forecast results
        forecast_results = forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(len(test))
        
        # Plot and save forecast
        plt.figure(figsize=(12, 6))
        plt.plot(prophet_data['ds'], prophet_data['y'], label='Actual')
        plt.plot(forecast['ds'], forecast['yhat'], color='red', label='Forecast')
        plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], color='pink', alpha=0.3)
        plt.title("Energy Consumption Forecast")
        plt.xlabel("Date")
        plt.ylabel("Energy Consumption (kWh)")
        plt.legend()
        
        # Ensure plots directory exists
        os.makedirs('plots', exist_ok=True)
        
        # Save plot
        plot_path = 'plots/forecast_plot.png'
        plt.savefig(plot_path)
        plt.close()
        
        # Convert forecast results to a JSON-serializable format
        forecast_json = forecast_results.to_dict(orient='records')
        for item in forecast_json:
            item['ds'] = item['ds'].isoformat()
        
        return {
            "forecast_data": forecast_json,
            "plot_path": plot_path,
            "total_forecast_points": len(forecast_results),
            "input_file": file_path
        }
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/forecast-plot")
async def get_forecast_plot():
    plot_path = 'plots/forecast_plot.png'
    if os.path.exists(plot_path):
        return FileResponse(plot_path, media_type="image/png")
    raise HTTPException(status_code=404, detail="Plot not found")